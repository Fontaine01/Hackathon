{"cells":[{"cell_type":"markdown","id":"b48f8a4e-faea-4589-b4b7-fbedfafaf19e","metadata":{"id":"b48f8a4e-faea-4589-b4b7-fbedfafaf19e"},"source":["# Task 2: Why are the predictions to good (/bad)?"]},{"cell_type":"markdown","id":"527419fe-8e73-4bd4-bde5-28cdcc92a861","metadata":{"id":"527419fe-8e73-4bd4-bde5-28cdcc92a861"},"source":["## Question"]},{"cell_type":"markdown","id":"4902aa2a-1c11-4310-bc04-b66d958cf2d3","metadata":{"id":"4902aa2a-1c11-4310-bc04-b66d958cf2d3"},"source":["### Proposition of solution\n","\n","Below, we give an proposition of code to tackle that above problem.\n","\n","Here's an example of how you can modify your code to incorporate stratified sampling using the train_test_split function from scikit-learn."]},{"cell_type":"markdown","id":"1ae778c4-8eaa-4b28-91f9-58004a71f914","metadata":{"id":"1ae778c4-8eaa-4b28-91f9-58004a71f914"},"source":["> I ran the following code for a binary classification task w/ an SVM in both R (first sample) and Python (second example).\n",">\n","> Given randomly generated data (X) and response (Y), this code performs leave group out cross validation 1000 times. Each entry of Y is therefore the mean of the prediction across CV iterations.\n",">\n","> Computing area under the curve should give ~0.5, since X and Y are completely random. However, this is not what we see. Area under the curve is frequently significantly higher than 0.5. The number of rows of X is very small, which can obviously cause problems.\n",">\n","> Any idea what could be happening here? I know that I can either increase the number of rows of X or decrease the number of columns to mediate the problem, but I am looking for other issues."]},{"cell_type":"markdown","id":"7eecb359-6799-4523-9cdd-05187e1230b2","metadata":{"id":"7eecb359-6799-4523-9cdd-05187e1230b2"},"source":["```R\n","Y=as.factor(rep(c(1,2), times=14))\n","X=matrix(runif(length(Y)*100), nrow=length(Y))\n","\n","library(e1071)\n","library(pROC)\n","\n","colnames(X)=1:ncol(X)\n","iter=1000\n","ansMat=matrix(NA,length(Y),iter)\n","for(i in seq(iter)){    \n","    #get train\n","\n","    train=sample(seq(length(Y)),0.5*length(Y))\n","    if(min(table(Y[train]))==0)\n","    next\n","\n","    #test from train\n","    test=seq(length(Y))[-train]\n","\n","    #train model\n","    XX=X[train,]\n","    YY=Y[train]\n","    mod=svm(XX,YY,probability=FALSE)\n","    XXX=X[test,]\n","    predVec=predict(mod,XXX)\n","    RFans=attr(predVec,'decision.values')\n","    ansMat[test,i]=as.numeric(predVec)\n","}\n","\n","ans=rowMeans(ansMat,na.rm=TRUE)\n","\n","r=roc(Y,ans)$auc\n","print(r)\n","```"]},{"cell_type":"markdown","id":"d14e4617-608b-4749-9ec5-edf15814f5bf","metadata":{"id":"d14e4617-608b-4749-9ec5-edf15814f5bf"},"source":["Similarly, when I implement the same thing in Python I get similar results.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"85b164c4-e490-4107-a1b4-1a8c282268bd","metadata":{"id":"85b164c4-e490-4107-a1b4-1a8c282268bd"},"outputs":[],"source":["## To ensure the following code you gave to work, we have to import the necessary libraries.\n","## Let's do and importing the necessary libraries for the code to work\n","import numpy as np\n","from sklearn.metrics import roc_curve,auc\n","from sklearn.svm import SVC"]},{"cell_type":"code","execution_count":null,"id":"0cf44d8d-ca36-4d6b-bafd-78cade069751","metadata":{"id":"0cf44d8d-ca36-4d6b-bafd-78cade069751","outputId":"a16e07ee-c8e3-4221-96d9-4e8f4f6bad90"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8775510204081631\n"]}],"source":["Y = np.array([1, 2]*14) #To create a one dimensional array of \"[1,2]\" 14 times. So Y have 2*14=28 elements.\n","X = np.random.uniform(size=[len(Y), 100]) #here we are generating randomly and following the uniform law and two dimension (28,1000) array.\n","n_iter = 1000\n","ansMat = np.full((len(Y), n_iter), np.nan) #here we contruct and array of of shape (28,1000) with a floating value \"nan\"\n","for i in range(n_iter):\n","    # Get train/test index\n","    train = np.random.choice(range(len(Y)), size=int(0.5*len(Y)), replace=False, p=None) #we generates a random sample taking between the range(len(y)\n","    if len(np.unique(Y)) == 1:\n","        continue\n","    test = np.array([i for i in range(len(Y)) if i not in train])\n","    # train model\n","    mod = SVC(probability=False)\n","    mod.fit(X=X[train, :], y=Y[train])\n","    # predict and collect answer\n","    ansMat[test, i] = mod.predict(X[test, :])\n","ans = np.nanmean(ansMat, axis=1)\n","fpr, tpr, thresholds = roc_curve(Y, ans, pos_label=1)\n","print(auc(fpr, tpr))"]},{"cell_type":"markdown","id":"504cde2c-c5fd-4bc8-8aba-efb044d31198","metadata":{"id":"504cde2c-c5fd-4bc8-8aba-efb044d31198"},"source":["## Answer"]},{"cell_type":"markdown","id":"6bffc1fe-fa56-488a-b0ee-2a4e06a189d0","metadata":{"id":"6bffc1fe-fa56-488a-b0ee-2a4e06a189d0"},"source":["The issue with encountering with the AUC-ROC metric being significantly higher than 0.5 despite using completely random data can be attributed to the way the train-test splits are generated in the. Ok Let's have a closer look where we are splitting the tarin test:\n","\n","train = np.random.choice(range(len(Y)), size=int(0.5*len(Y)), replace=False, p=None)\n","\n","In this line, we randomly select indices for the training set using np.random.choice. The probability p parameter is set to None, which means each element in target or response Y has an equal chance of being selected. However, this does not take into account the class distribution of the data.\n","\n","Since the class labels in Y are alternating between 1 and 2, it's possible for the training set to contain a disproportionate number of instances from one class compared to the other. This imbalance in the training set can lead to biased predictions and, consequently, inflated AUC-ROC values.\n","\n","To address this issue, you can modify your code to ensure a balanced distribution of classes in the training set. One approach is to use stratified sampling, which ensures that the proportion of each class is preserved in the training set.\n","\n","Below I give my proposition code to adress this issue\n"]},{"cell_type":"code","execution_count":null,"id":"2f187bab-13f8-410b-b8fa-f53ff351d481","metadata":{"id":"2f187bab-13f8-410b-b8fa-f53ff351d481","outputId":"5041fc34-d616-42e0-a5fa-8edf7ca81d3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5\n"]}],"source":["import numpy as np\n","from sklearn.metrics import roc_curve,auc\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","\n","Y = np.array([1, 2]*14)\n","X = np.random.uniform(size=[len(Y), 100])\n","n_iter = 1000\n","ansMat = np.full((len(Y), n_iter), np.nan)\n","\n","# Split the data into train and test sets using stratified sampling\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, stratify=Y, random_state=42)\n","\n","# Perform your model training and prediction on the stratified train and test sets\n","mod = SVC(probability=False)\n","mod.fit(X=X_train, y=Y_train)\n","ansMat = mod.predict(X_test)\n","\n","# Calculate AUC-ROC on the stratified test set\n","fpr, tpr, thresholds = roc_curve(Y_test, ansMat, pos_label=1)\n","print(auc(fpr, tpr))"]},{"cell_type":"markdown","id":"df4bf8ae-cac6-4068-a753-c4aaa23c9515","metadata":{"id":"df4bf8ae-cac6-4068-a753-c4aaa23c9515"},"source":["By using train_test_split with the stratify parameter set to Y, the function will ensure that the training and test sets have a balanced class distribution. This should provide more accurate and reliable AUC-ROC results, even with a small dataset."]},{"cell_type":"markdown","id":"fcfb3ad1-3f67-403e-9ee4-775b67f76660","metadata":{"id":"fcfb3ad1-3f67-403e-9ee4-775b67f76660"},"source":["## Feedback"]},{"cell_type":"markdown","id":"867962a5-b639-4d39-882c-5a42a68e891c","metadata":{"id":"867962a5-b639-4d39-882c-5a42a68e891c"},"source":["Was this exercise is difficult or not? In either case, briefly describe why."]},{"cell_type":"markdown","id":"6164770c-189f-446b-8033-32c3caa103a1","metadata":{"id":"6164770c-189f-446b-8033-32c3caa103a1"},"source":["This exercice was a bit difficult. In fact, debugging the code of someone is always the difficult task. So after went trough each line of code and master each of them, I finally understand what can be the problem and proposed my own sugestion."]},{"cell_type":"code","execution_count":null,"id":"44e24d48-7fc3-4d06-b1ca-b15e12296322","metadata":{"id":"44e24d48-7fc3-4d06-b1ca-b15e12296322"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}